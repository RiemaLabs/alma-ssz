package rl

import (
	"fmt"
	"math/rand"
	"reflect"
	"time"

	"alma.local/ssz/concretizer"
	"alma.local/ssz/domains"
	"alma.local/ssz/encoding"
	"alma.local/ssz/feedback" // New import for RuntimeSignature
	"alma.local/ssz/fuzzer"
	"alma.local/ssz/internal/analyzer" // New import for analyzer
	"alma.local/ssz/spec"
	"github.com/ferranbt/fastssz"
)

// Seed the random number generator once for the package
func init() {
	rand.Seed(time.Now().UnixNano())
}

// State represents the complete state of the RL environment at a given time.
type State struct {
	Signature     feedback.RuntimeSignature
	RewardHistory []float64 // History of rewards, for plotting/analysis
	TotalCoverage float64
	NewCoverage   float64
	HistorySummary []float64 // Summary of past observations/rewards
}

// ToObservation converts the current State into an Observation suitable for the RL agent.
// This is where the feature engineering for the RL agent's input happens.
func (s *State) ToObservation() Observation {
	// For now, let's use HistorySummary as the primary observation vector.
	// In a more sophisticated setup, this would combine various aspects of the state.
	return Observation{Vector: s.HistorySummary}
}

// NewState creates a new State object.
func NewState(sig feedback.RuntimeSignature, rewardHistory []float64, totalCov, newCov float64, historySummary []float64) *State {
	return &State{
		Signature:     sig,
		RewardHistory: rewardHistory,
		TotalCoverage: totalCov,
		NewCoverage:   newCov,
		HistorySummary: historySummary,
	}
}

// Observation is the state observed by the agent.
type Observation struct {
	Vector []float64 // A vector of numerical features describing the environment state.
}

// StepInfo provides additional information about the step.
type StepInfo struct {
	BugFound      bool
	RewardDetails feedback.RuntimeSignature
}


// FuzzingEnv represents the environment in which the RL agent operates.
// It encapsulates the SSZ schema, the analyzer, concretizer, and a conceptual fuzzer/tracer.
type FuzzingEnv struct {
	Analyzer    *spec.GenericAnalyzer
	KLAnalyzer  *analyzer.Analyzer // New: Analyzer for KL-Divergence scores
	Concretizer *concretizer.Concretizer
	TargetSchema interface{} // The SSZ struct being fuzzed (e.g., *schemas.BeaconState)
	Domains     []domains.Domain // Domains generated by the analyzer for the target schema
	EncodingCtx *EncodingContext // The flattened action space derived from domains

	// This is now a real Fuzzer interface, not a mock tracer.
	Fuzzer        fuzzer.Fuzzer 
	CurrentState  *State
	EpisodeReward float64
	StepsCount    int
	MaxSteps      int
	BatchSize     int // New: Number of inputs to generate and execute per Step
}

// NewFuzzingEnv creates a new FuzzingEnv for a given SSZ schema.
func NewFuzzingEnv(targetSchema interface{}, maxSteps int, batchSize int, d_ctx int) (*FuzzingEnv, error) {
	specAnalyzer := spec.NewGenericAnalyzer() // Renamed from analyzer
	domainsList, err := specAnalyzer.GetDomains(targetSchema)
	if err != nil {
		return nil, fmt.Errorf("failed to analyze schema: %w", err)
	}

	encodingCtx := NewEncodingContext(domainsList) // Use from action_space
	if encodingCtx.ActionCount() == 0 {
		return nil, fmt.Errorf("no actions found for the given schema")
	}

	// Use InProcessFuzzer for real, high-performance fuzzing
	realFuzzer, err := fuzzer.NewInProcessFuzzer(targetSchema) 
	if err != nil {
		return nil, fmt.Errorf("failed to create in-process fuzzer: %w", err)
	}

	env := &FuzzingEnv{
		Analyzer:      specAnalyzer,
		KLAnalyzer:    analyzer.NewAnalyzer(), // Initialize KL-Divergence analyzer using package name
		Concretizer:   concretizer.New(),
		TargetSchema:  targetSchema,
		Domains:       domainsList,
		EncodingCtx:   encodingCtx,
		Fuzzer:        realFuzzer, // Use the real fuzzer here
		MaxSteps:      maxSteps,
		BatchSize:     batchSize, // Initialize BatchSize
		// Initial empty state with RuntimeSignature and empty historySummary
		CurrentState:  NewState(feedback.RuntimeSignature{}, []float64{}, 0.0, 0.0, make([]float64, d_ctx)), 
		EpisodeReward: 0.0,
		StepsCount:    0,
	}
	return env, nil
}

// Reset initializes the environment for a new episode and returns the initial state.
func (env *FuzzingEnv) Reset(initialHistorySummary []float64) *State {
	env.EpisodeReward = 0.0
	env.StepsCount = 0
	// Reset tracer, coverage, etc.
	env.Fuzzer.Reset() // Call reset on the real fuzzer
	env.KLAnalyzer = analyzer.NewAnalyzer() // Re-initialize (Reset) the KL analyzer for a new episode
	// Return a clean initial state with the provided history summary
	env.CurrentState = NewState(feedback.RuntimeSignature{}, []float64{}, 0.0, 0.0, initialHistorySummary) 
	return env.CurrentState
}

// Step executes one step in the environment given a batch of actions selected by the agent.
func (env *FuzzingEnv) Step(actions []Action) (*State, float64, bool, int, error) { // actions is now a slice
	if len(actions) != env.BatchSize {
		return env.CurrentState, -1.0, true, 0, fmt.Errorf("number of actions in batch (%d) does not match environment batch size (%d)", len(actions), env.BatchSize)
	}

	batchRuntimeSignature := feedback.RuntimeSignature{} // Aggregate signature for the batch
	batchBugTriggered := false
	batchReward := 0.0
	bugTriggerStep := 0 // Initialize bugTriggerStep

	batchTraces := make([][]analyzer.TraceEntry, 0, env.BatchSize)

	for _, action := range actions { // Process each action in the batch
		// 1. Convert Action (chosen by ID) to a partial EncodingMatrix for the Concretizer
		matrix := encoding.NewEncodingMatrix(reflect.TypeOf(env.TargetSchema).Elem().Name())
		
		encCtxAction, err := env.EncodingCtx.GetActionByIndex(action.ID)
		if err != nil {
			fmt.Printf("Warning: Error getting EncodingContextAction for ID %d: %v\n", action.ID, err)
			batchRuntimeSignature.NonBugErrorCount++
			continue
		}
		matrix.Select(encCtxAction.FieldName, encCtxAction.AspectID, encCtxAction.BucketID)

	// Create a new instance of the target schema
	newInput := reflect.New(reflect.TypeOf(env.TargetSchema).Elem()).Interface()
		mutations, err := env.Concretizer.Concretize(newInput, matrix, env.Domains)
		if err != nil {
			// Penalty for failed concretization
			batchReward -= 5.0
			batchRuntimeSignature.NonBugErrorCount++ // Count this as a non-bug error for the batch
			continue // Skip SSZ encoding and execution if concretization fails
		}
		
		// Apply mutations logic (Placeholder for now, as discussed)
		_ = mutations

		// 3. Encode to SSZ bytes
		marshaler, ok := newInput.(ssz.Marshaler)
		if !ok {
			batchReward -= 5.0
			batchRuntimeSignature.NonBugErrorCount++ // Count this as a non-bug error for the batch
			return env.CurrentState, batchReward, true, bugTriggerStep, fmt.Errorf("newInput is not a marshaler")
		}
		
		sszBytes, err := marshaler.MarshalSSZ() 
		if err != nil {
			batchReward -= 5.0
			batchRuntimeSignature.NonBugErrorCount++ // Count this as a non-bug error for the batch
			return env.CurrentState, batchReward, true, bugTriggerStep, fmt.Errorf("failed to marshal ssz: %w", err)
		}

		// Apply mutations (Dirty Booleans etc.)
		if len(mutations) > 0 {
			sszBytes, err = ApplyMutations(sszBytes, mutations, env.TargetSchema)
			if err != nil {
				// Log error but maybe continue with unmutated bytes?
				// Or penalize.
				// fmt.Printf("Mutation failed: %v\n", err)
			}
		}

		// 4. Execute and get feedback for single input, including trace
		signature, bugTriggeredIndividual, _, trace := env.Fuzzer.Execute(sszBytes) 
		
		// 5. Aggregate results for the batch
		batchRuntimeSignature.RoundtripSuccessCount += signature.RoundtripSuccessCount
		batchRuntimeSignature.NonBugErrorCount      += signature.NonBugErrorCount
		batchRuntimeSignature.BugFoundCount         += signature.BugFoundCount
		if bugTriggeredIndividual {
			batchBugTriggered = true
			if bugTriggerStep == 0 { // Record the first time a bug is triggered in the current step
				bugTriggerStep = env.StepsCount + 1
			}
		}
		batchTraces = append(batchTraces, trace)
	} // End of batch processing loop
	
	// --- Calculate Reward for the batch ---
	// R_t = R^KL_t + R^bug_t (as per Pipeline 3.5)

	// R^bug_t:
	if batchBugTriggered {
		batchReward += 100.0 // High reward for finding a bug in the batch
	}

	// R^KL_t: Calculate KL score for the entire batch's traces
	klScore := 0.0
	for _, trace := range batchTraces {
		// We update the KLAnalyzer with all traces from the batch *before* scoring,
		// or rather, we score each trace against the *current* global model.
		// For the Pipeline, it sounds like Q_t (current batch distribution) vs P_hist (history).
		// For simplicity, we use the Analyzer's existing ScoreTrace which does trace-by-trace update.
		klScore += env.KLAnalyzer.ScoreTrace(trace, true) // Score and update global model
	}
	// Average KL score per input
	avgKLScore := klScore / float64(env.BatchSize)

	// Normalize KL score by batch size, or scale appropriately
	batchReward += avgKLScore * 25.0 // Increased scaling factor to amplify signal

	// Add a small penalty for each batch step to encourage efficiency
	batchReward -= float64(env.BatchSize) * 0.1 

	env.EpisodeReward += batchReward
	env.StepsCount++

	// 6. Update State with batch aggregated data.
	newHistorySummary := make([]float64, d_ctx)

	// Populate the observation vector with relevant state information
	// Simple approach: Fill first few dimensions with key metrics, rest with zeros for now
	if d_ctx >= 1 {
		newHistorySummary[0] = env.Fuzzer.TotalCoverage() // Total coverage
	}
	if d_ctx >= 2 {
		newHistorySummary[1] = avgKLScore // Average KL score from this batch
	}
	if d_ctx >= 3 {
		newHistorySummary[2] = float64(batchRuntimeSignature.BugFoundCount) // Bugs found in this batch
	}
	if d_ctx >= 4 {
		newHistorySummary[3] = float64(batchRuntimeSignature.NonBugErrorCount) // Non-bug errors in this batch
	}
	newRewardHistory := append(env.CurrentState.RewardHistory, batchReward)
	if len(newRewardHistory) > 10 { // Keep reward history to a fixed size
		newRewardHistory = newRewardHistory[len(newRewardHistory)-10:]
	}
	// Add recent rewards to the history summary, if space allows
	// Max length of rewardHistory is 10, so it can take up to 10 dimensions.
	for idx, r := range newRewardHistory {
		if d_ctx >= 5+idx {
			newHistorySummary[4+idx] = r
		} else {
			break
		}
	}
	// Remaining dimensions will be zero-initialized.
	// Repurposed NewCoverage to store Average KL Score for visualization
	env.CurrentState = NewState(batchRuntimeSignature, newRewardHistory, env.Fuzzer.TotalCoverage(), avgKLScore, newHistorySummary)

	// 7. Check if episode is done
	done := env.StepsCount >= env.MaxSteps || batchBugTriggered

	return env.CurrentState, batchReward, done, bugTriggerStep, nil
}